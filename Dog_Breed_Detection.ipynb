{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog Breed Detection 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CEhUNtlkGMAk5dpa_yjkn592X7lw-K5H",
      "authorship_tag": "ABX9TyOj8BlUN11oGOhUX/u61sdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/30Dev/Dog-Breed-Detection/blob/main/Dog_Breed_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP2MFjpSzwLk"
      },
      "source": [
        "pip install livelossplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P0GNFOM12Gu"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "import cv2\n",
        "import PIL\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plotly for the interactive viewer (see last section)\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten,BatchNormalization,Activation\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import gc\n",
        "import skimage.io\n",
        "from livelossplot import PlotLossesKeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tydLsqZd27iX"
      },
      "source": [
        "#### Mounting Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmS-7Mzp2BWz"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAfyRf8K19fm"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_src = '/content/drive/MyDrive/Dog Breed Detection/train'\n",
        "test_src = '/content/drive/MyDrive/Dog Breed Detection/test'\n",
        "\n",
        "train_labels = pd.read_csv('/content/drive/MyDrive/Dog Breed Detection/labels.csv', index_col = 'id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJm9sMd22WIG"
      },
      "source": [
        "import os\n",
        "\n",
        "train_size = len(os.listdir(train_src))\n",
        "test_size = len(os.listdir(test_src))\n",
        "\n",
        "print(train_size,test_size)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hSeovPF3Io2"
      },
      "source": [
        "target, dog_breeds = pd.factorize(train_labels['breed'], sort = True)\n",
        "train_labels['target'] = target\n",
        "\n",
        "print(dog_breeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaaXPLAN3wOb"
      },
      "source": [
        "display(train_labels.head())\n",
        "display(train_labels.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tXUEtP93wSK"
      },
      "source": [
        "train_labels['breed'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Dzw23K3wVL"
      },
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "train_labels['breed'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfYmyJuz34wq"
      },
      "source": [
        "\n",
        "Prepare the Train and Test Data Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9shXYC334SU"
      },
      "source": [
        "data_dir = pathlib.Path('/content/drive/MyDrive/Dog Breed Detection 1')\n",
        "data_dir.mkdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW7x-tX63-3R"
      },
      "source": [
        "train_dir = data_dir / 'train'\n",
        "test_dir = data_dir / 'test'\n",
        "\n",
        "train_dir.mkdir()\n",
        "test_dir.mkdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANg7wGQy3-6n"
      },
      "source": [
        "## Create a directory for each dog breed classes\n",
        "for breed in dog_breeds:\n",
        "    breed_dir = train_dir / breed\n",
        "    breed_dir.mkdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4yyGBqM3-9A"
      },
      "source": [
        "for root, dirs, files in os.walk(train_src):\n",
        "    for file in files:\n",
        "        imgName = file.split('.')[0]\n",
        "        src_file = os.path.join(train_src, file)\n",
        "        destination = os.path.join(train_dir, train_labels.loc[imgName, 'breed'])\n",
        "        shutil.copy2(src_file, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK05Nhz64cIU"
      },
      "source": [
        "shutil.copytree(test_src, test_dir / 'images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdT6MokG4f33"
      },
      "source": [
        "\n",
        "Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVuhfyJW4gA7"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn_Zby_L4wcx"
      },
      "source": [
        "Prepare the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8xqKJ7C4gED"
      },
      "source": [
        "train_ds = image_dataset_from_directory(\n",
        "  directory = train_dir,\n",
        "  labels = 'inferred',\n",
        "  label_mode='int',\n",
        "  batch_size=BATCH_SIZE,\n",
        "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "  shuffle = True,\n",
        "  seed=1234,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb76YV0e43b8"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(len(class_names))\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqg7lVe543e2"
      },
      "source": [
        "val_ds = image_dataset_from_directory(\n",
        "  directory = train_dir,\n",
        "  labels = 'inferred',\n",
        "  label_mode='int',\n",
        "  batch_size=BATCH_SIZE,\n",
        "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "  shuffle = True,\n",
        "  seed=1234,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFXwdU-z43hy"
      },
      "source": [
        "test_ds = image_dataset_from_directory(\n",
        "  directory = test_dir,\n",
        "  label_mode= None,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "  shuffle = False,\n",
        "  seed=1234\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO2N5T1J4-x6"
      },
      "source": [
        "Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q5WbLGy49S-"
      },
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "#   print(labels)\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(dog_breeds[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YObUSAbk49WF"
      },
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for images, labels in val_ds.take(1):\n",
        "#   print(labels)\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(dog_breeds[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUuBqdXW49ZH"
      },
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for images in test_ds.take(1):\n",
        "#   print(labels)\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#     plt.title(dog_breeds[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqzbOY7j5KBj"
      },
      "source": [
        "\n",
        "**Configure the dataset for performance**\n",
        "\n",
        "Let's make sure to use buffered prefetching, so \n",
        "we can yield data from disk without having I/O become blocking. These are two important methods we should use when loading data.\n",
        "\n",
        ".cache() keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        ".prefetch() overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L2Kha9S5T3n"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuhULgh26u5q"
      },
      "source": [
        "\n",
        "Data Augmentation Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhTp5HRg6ubP"
      },
      "source": [
        "data_augmentation = Sequential(\n",
        "  [\n",
        "    preprocessing.Resizing(299,299),\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    preprocessing.RandomRotation(0.1),\n",
        "    preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0C7S_9C6y9p"
      },
      "source": [
        "\n",
        "\n",
        "Let's visualize what the first image of the first batch looks like after various random transformations:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Dx49BK61ZV"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    first_image = images[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(\n",
        "            tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "        plt.title(dog_breeds[labels[0]])\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bjq_Qs465Nj"
      },
      "source": [
        "Build a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFi9rcu7664W"
      },
      "source": [
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299,299,3)) \n",
        "# display(base_model.summary())\n",
        "rescale=tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5,offset=-1)\n",
        "# train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional Xception layers\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=(299, 299, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x) ##  tf.keras.applications.xception.preprocess_input\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here by passing `training=False`.\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "#     adding extra dense layer\n",
        "#     x = Dense(1024, activation='relu')(x)\n",
        "#     x = Dropout(.7)(x)\n",
        "#     x = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dropout(.5)(x)\n",
        "outputs = Dense(120, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "display(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eERFLDf87HJ_"
      },
      "source": [
        "Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v6xXaq57Gwj"
      },
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK1Rz8d_7OW7"
      },
      "source": [
        "EarlyStop_callback = EarlyStopping(min_delta=0.001, patience=10, restore_best_weights=True)\n",
        "\n",
        "# # DECREASE LEARNING RATE EACH EPOCH\n",
        "# annealer = LearningRateScheduler(lambda epoch: 1e-5 * 0.95 ** epoch, verbose=1)\n",
        "\n",
        "# cb=[PlotLossesKeras(), annealer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iAM822w7Oaq"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=N_EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[EarlyStop_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuovbpvj7Odi"
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.xticks(list(range(20)))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xticks(list(range(20)))\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOio3Eah7ZbD"
      },
      "source": [
        "Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCoP5Ksg7azT"
      },
      "source": [
        "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
        "# since we passed `training=False` when calling it. This means that\n",
        "# the batchnorm layers will not update their batch statistics.\n",
        "# This prevents the batchnorm layers from undoing all the training\n",
        "# we've done so far.\n",
        "base_model.trainable = True\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLQ3S7cn7ent"
      },
      "source": [
        "print(\"Number of layers in the base model: \", len(base_model.layers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcfgA-9S7eq2"
      },
      "source": [
        "fine_tune_from = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_from]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZWTtSfQ7euD"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-8ziRh17ew-"
      },
      "source": [
        "FINE_TUNE_EPOCHS = 10\n",
        "fine_tune_history = model.fit(train_ds,\n",
        "                              epochs = FINE_TUNE_EPOCHS + history.epoch[-1],\n",
        "                              initial_epoch = history.epoch[-1] + 1,\n",
        "                              validation_data = val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRWaBX567n6U"
      },
      "source": [
        "accuracy += history_fine.history['accuracy']\n",
        "val_accuracy += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNks3Zb77n9a"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([EPOCHS-1,EPOCHS-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([EPOCHS-1,EPOCHS-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIMBHqt-7tzB"
      },
      "source": [
        "Predict on Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88w14yGY7oAV"
      },
      "source": [
        "del train_ds, val_ds, train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKF7thGh7xrT"
      },
      "source": [
        "file_paths = test_ds.file_paths\n",
        "# print(file_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDYgFjHd7xua"
      },
      "source": [
        "predictions = model.predict(\n",
        "    test_ds,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    verbose=1         \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TmOsGc77xxE"
      },
      "source": [
        "print(predictions.shape)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmlofspe7x3C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}